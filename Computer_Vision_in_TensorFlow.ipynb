{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Computer Vision in TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EvidenceN/Computer-Vision-TensorFlow/blob/master/Computer_Vision_in_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjACihw9PPd8",
        "colab_type": "code",
        "outputId": "2eb17f1f-9ddd-44df-91e4-faf7828dd709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAwbiYhPhbCE",
        "colab_type": "code",
        "outputId": "20016855-96c5-4f0d-9e26-7d54ae8711c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "# fashion mnist dataset is a 28x28 array of greyscale images. \n",
        "# the image labels are numbers. we use numbers as labels to avoid bias. \n",
        "# avoiding bias in machine learning: https://developers.google.com/machine-learning/fairness-overview/\n",
        "# clothing data set has 10 categories/10 classes. \n",
        "\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMi1W1d9wKNV",
        "colab_type": "code",
        "outputId": "956a0ff0-a670-43a6-ba58-f448f8373a32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.imshow(train_images[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f530c7f5630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8qp_6efweL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_labels[0])\n",
        "\n",
        "# The data for a particular image is a grid of values from\n",
        "# zero to 255 with pixel Grayscale values.\n",
        "\n",
        "print(train_images[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZHV7PiVyDs2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "You'll notice that all of the values in the number are between 0 and 255. If we are training a neural network, for various reasons it's easier if we treat all values as between 0 and 1, a process called 'normalizing'...and fortunately in Python it's easy to normalize a list like this without looping. You do it like this:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0TBwon4xJf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images/255.0\n",
        "test_images = test_images/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duMuAFNmyWOZ",
        "colab_type": "code",
        "outputId": "0040b1a0-4c67-45be-9667-6a707c74ef06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "# Sequential with 3 layers instead of 1 layer like previous lesson. \n",
        "# Flatten takes the 28 X 28 square and turn it into a simple linear array\n",
        "# hidden layer takes the 784 values of an angle boot and turn it into the value 9\n",
        "# see hiden layer image https://drive.google.com/file/d/1pUiscWVrUs9UHHn8nnGVpk1ZSNbcQXT9/view?usp=sharing\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)), # shape we should expect the data to be in. \n",
        "    keras.layers.Dense(128, activation=tf.nn.relu), # hidden layer. # 128 neurons. # variables in a function, x1, x2, x3, e.t.c\n",
        "    keras.layers.Dense(10, activation=tf.nn.softmax) #10 neurons because of 10 classes of clothin in the dataset.\n",
        "])\n",
        "\n",
        "# input layer in the shape of the data\n",
        "# output layer in the shape of the classes\n",
        "# and a hidden layer to define the relationship between input and output layer. "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj3s1uR1ygkg",
        "colab_type": "text"
      },
      "source": [
        "Sequential: That defines a SEQUENCE of layers in the neural network\n",
        "\n",
        "Flatten: Remember earlier where our images were a square, when you printed them out? Flatten just takes that square and turns it into a 1 dimensional set.\n",
        "\n",
        "Dense: Adds a layer of neurons\n",
        "\n",
        "Each layer of neurons need an activation function to tell them what to do. There's lots of options, but just use these for now.\n",
        "\n",
        "Relu effectively means \"If X>0 return X, else return 0\" -- so what it does it it only passes values 0 or greater to the next layer in the network.\n",
        "\n",
        "Softmax takes a set of values, and effectively picks the biggest one, so, for example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it saves you from fishing through it looking for the biggest value, and turns it into [0,0,0,0,1,0,0,0,0] -- The goal is to save a lot of coding!\n",
        "\n",
        "The next thing to do, now the model is defined, is to actually build it. You do this by compiling it with an optimizer and loss function as before -- and then you train it by calling *model.fit * asking it to fit your training data to your training labels -- i.e. have it figure out the relationship between the training data and its actual labels, so in future if you have data that looks like the training data, then it can make a prediction for what that data would look like.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as-v9ksly_Tf",
        "colab_type": "code",
        "outputId": "472b96fb-6da0-4b3c-fa45-877f5be4595b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.compile(optimizer = tf.train.AdamOptimizer(),\n",
        "             loss = 'sparse_categorical_crossentropy',\n",
        "             metrics = ['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 4s 75us/sample - loss: 0.5006 - acc: 0.8244\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.3778 - acc: 0.8641\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.3404 - acc: 0.8768\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3161 - acc: 0.8842\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.2969 - acc: 0.8894\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f530ba8d2e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De8Ejeab0Pm1",
        "colab_type": "text"
      },
      "source": [
        "Once it's done training -- you should see an accuracy value at the end of the final epoch. It might look something like 0.9098. This tells you that your neural network is about 91% accurate in classifying the training data. I.E., it figured out a pattern match between the image and the labels that worked 91% of the time. Not great, but not bad considering it was only trained for 5 epochs and done quite quickly.\n",
        "\n",
        "But how would it work with unseen data? That's why we have the test images. We can call model.evaluate, and pass in the two sets, and it will report back the loss for each. Let's give it a try:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVvh7i_m3A7i",
        "colab_type": "code",
        "outputId": "08560b9b-9a44-4976-c07e-e2e9caba3293",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 33us/sample - loss: 0.3807 - acc: 0.8591\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.38073816514015196, 0.8591]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QeWkpX23SMG",
        "colab_type": "text"
      },
      "source": [
        "It shows an accuracy of 86%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APfRTxbj3u8C",
        "colab_type": "text"
      },
      "source": [
        "# Exploration Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d_vneK730kI",
        "colab_type": "text"
      },
      "source": [
        "It creates a set of classifications for each of the test images, and then prints the first entry in the classifications. The output is a list of numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy2X8V___XlK",
        "colab_type": "text"
      },
      "source": [
        "**Excercise 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXFOG-4337yM",
        "colab_type": "code",
        "outputId": "ed3a0396-ce4d-4e45-c924-72aec8ae88aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "classifications = model.predict(test_images)\n",
        "print(classifications[11])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3.2419046e-06 1.9486668e-05 1.0543654e-05 5.1685670e-06 9.2126007e-05\n",
            " 9.9832612e-01 4.1944659e-05 5.6005927e-04 7.5231721e-05 8.6616335e-04]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SKVKeuP_1Sx",
        "colab_type": "code",
        "outputId": "50ee1856-1247-4bbf-d870-2313be485a73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(test_labels[11])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM0GztkUCN7w",
        "colab_type": "text"
      },
      "source": [
        "The output of the model is a list of 10 numbers. These numbers are a probability that the value being classified is the corresponding value, i.e. the first value in the list is the probability that the handwriting is of a '0', the next is a '1' etc. Notice that they are all VERY LOW probabilities.\n",
        "\n",
        "For the 7, the probability was .999+, i.e. the neural network is telling us that it's almost certainly a 7.\n",
        "\n",
        "**The 5th element on the list is the biggest, and ITEM 11 is labelled 5**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuJlABfeDizk",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 2. Experimenting with different values for the dense layer.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueXhPNkmCzqW",
        "colab_type": "code",
        "outputId": "e42272d1-f9c0-4e75-dc5a-472704182417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# getting the dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# loading the dataset into different variables\n",
        "(training_images, training_labels), (testing_images, testing_labels) = mnist.load_data()\n",
        "\n",
        "# standardizing the dataset to have 0's and 1's\n",
        "# training and testing images has numbers between 0 and 255\n",
        "training_images = training_images/255.0\n",
        "testing_images = testing_images/255.0\n",
        "\n",
        "# designing the model\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                            tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "                            tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "# building the model\n",
        "model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', \n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# fitting the training data to the training labels\n",
        "model.fit(training_images, training_labels, epochs = 5)\n",
        "\n",
        "# evaluating the accuracy of the model using testing data to see how well our\n",
        "# system was trained. \n",
        "model.evaluate(testing_images, testing_labels)\n",
        "\n",
        "# creating a classification for each of the test images. \n",
        "# The classification let's us know the probability of \n",
        "# which label the test image belongs to. is it a shoe, shirt, \n",
        "# but in this case, the classification is not shoe, shirt, e.t.c\n",
        "# but rather it is a number. \n",
        "# We are testing to see if our model can \n",
        "# classify the images into the appropriate categories/labels\n",
        "\n",
        "classifications = model.predict(testing_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(testing_labels[0])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 14s 226us/sample - loss: 0.1842 - acc: 0.9448\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 13s 216us/sample - loss: 0.0732 - acc: 0.9771\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 13s 218us/sample - loss: 0.0492 - acc: 0.9843\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 13s 217us/sample - loss: 0.0355 - acc: 0.9883\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 13s 217us/sample - loss: 0.0257 - acc: 0.9918\n",
            "10000/10000 [==============================] - 1s 94us/sample - loss: 0.0709 - acc: 0.9801\n",
            "[4.4031156e-09 1.1802603e-08 3.7656264e-08 1.8585199e-06 3.8147692e-12\n",
            " 3.0099482e-08 2.0999068e-13 9.9999619e-01 4.1933403e-09 1.8500493e-06]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXurH5AeR_0n",
        "colab_type": "code",
        "outputId": "36ab8eca-2289-4463-8f74-50d214407e7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        }
      },
      "source": [
        "# training with more epochs generates greater accuracy. \n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# getting the dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# loading the dataset into different variables\n",
        "(training_images, training_labels), (testing_images, testing_labels) = mnist.load_data()\n",
        "\n",
        "# standardizing the dataset to have 0's and 1's\n",
        "# training and testing images has numbers between 0 and 255\n",
        "training_images = training_images/255.0\n",
        "testing_images = testing_images/255.0\n",
        "\n",
        "# designing the model\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                            tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "                            tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "# building the model\n",
        "model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', \n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# fitting the training data to the training labels\n",
        "model.fit(training_images, training_labels, epochs = 15)\n",
        "\n",
        "# evaluating the accuracy of the model using testing data to see how well our\n",
        "# system was trained. \n",
        "model.evaluate(testing_images, testing_labels)\n",
        "\n",
        "# creating a classification for each of the test images. \n",
        "# The classification let's us know the probability of \n",
        "# which label the test image belongs to. is it a shoe, shirt, \n",
        "# but in this case, the classification is not shoe, shirt, e.t.c\n",
        "# but rather it is a number. \n",
        "# We are testing to see if our model can \n",
        "# classify the images into the appropriate categories/labels\n",
        "\n",
        "classifications = model.predict(testing_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(testing_labels[0])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 18s 296us/sample - loss: 0.1861 - acc: 0.9432\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 16s 259us/sample - loss: 0.0756 - acc: 0.9764\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 16s 271us/sample - loss: 0.0487 - acc: 0.9848\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 16s 264us/sample - loss: 0.0341 - acc: 0.9891\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 15s 251us/sample - loss: 0.0264 - acc: 0.9918\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 17s 288us/sample - loss: 0.0217 - acc: 0.9933\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 17s 284us/sample - loss: 0.0166 - acc: 0.9942\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 16s 264us/sample - loss: 0.0152 - acc: 0.9948\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 17s 278us/sample - loss: 0.0136 - acc: 0.9956\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 17s 279us/sample - loss: 0.0132 - acc: 0.9960\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 16s 273us/sample - loss: 0.0116 - acc: 0.9964\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 18s 307us/sample - loss: 0.0092 - acc: 0.9970\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 17s 285us/sample - loss: 0.0122 - acc: 0.9963\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 17s 281us/sample - loss: 0.0072 - acc: 0.9975\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 18s 292us/sample - loss: 0.0101 - acc: 0.9970\n",
            "10000/10000 [==============================] - 1s 121us/sample - loss: 0.1202 - acc: 0.9818\n",
            "[3.9845253e-18 7.9851549e-21 7.8515343e-19 2.4693209e-13 8.2168950e-25\n",
            " 4.6475216e-17 1.4905427e-21 1.0000000e+00 7.0705775e-19 5.4643760e-15]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOIAPONCUXpy",
        "colab_type": "code",
        "outputId": "662d4eb3-d2ac-44d0-ae0a-477c2ba0c430",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# training with too much epochs causes overfitting. because accuracy begins to \n",
        "# go down.\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# getting the dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# loading the dataset into different variables\n",
        "(training_images, training_labels), (testing_images, testing_labels) = mnist.load_data()\n",
        "\n",
        "# standardizing the dataset to have 0's and 1's\n",
        "# training and testing images has numbers between 0 and 255\n",
        "training_images = training_images/255.0\n",
        "testing_images = testing_images/255.0\n",
        "\n",
        "# designing the model\n",
        "# relu throws out anything that is negative. it doesn't activate anything below 0\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                            tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "                            tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "# building the model\n",
        "model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', \n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# fitting the training data to the training labels\n",
        "model.fit(training_images, training_labels, epochs = 30)\n",
        "\n",
        "# evaluating the accuracy of the model using testing data to see how well our\n",
        "# system was trained. \n",
        "model.evaluate(testing_images, testing_labels)\n",
        "\n",
        "# creating a classification for each of the test images. \n",
        "# The classification let's us know the probability of \n",
        "# which label the test image belongs to. is it a shoe, shirt, \n",
        "# but in this case, the classification is not shoe, shirt, e.t.c\n",
        "# but rather it is a number. \n",
        "# We are testing to see if our model can \n",
        "# classify the images into the appropriate categories/labels\n",
        "\n",
        "classifications = model.predict(testing_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(testing_labels[0])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 16s 260us/sample - loss: 0.1867 - acc: 0.9440\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 16s 266us/sample - loss: 0.0746 - acc: 0.9768\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 16s 267us/sample - loss: 0.0498 - acc: 0.9839\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 16s 270us/sample - loss: 0.0336 - acc: 0.9892\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 16s 266us/sample - loss: 0.0272 - acc: 0.9911\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 16s 264us/sample - loss: 0.0196 - acc: 0.9937\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 16s 267us/sample - loss: 0.0184 - acc: 0.9939\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 16s 267us/sample - loss: 0.0143 - acc: 0.9954\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 15s 257us/sample - loss: 0.0132 - acc: 0.9956\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 16s 264us/sample - loss: 0.0117 - acc: 0.9962\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 16s 260us/sample - loss: 0.0117 - acc: 0.9963\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 15s 253us/sample - loss: 0.0113 - acc: 0.9966\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 15s 258us/sample - loss: 0.0094 - acc: 0.9969\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 15s 254us/sample - loss: 0.0093 - acc: 0.9969\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 16s 259us/sample - loss: 0.0102 - acc: 0.9966\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 16s 274us/sample - loss: 0.0078 - acc: 0.9978\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 16s 259us/sample - loss: 0.0096 - acc: 0.9967\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 16s 261us/sample - loss: 0.0062 - acc: 0.9980\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 16s 265us/sample - loss: 0.0075 - acc: 0.9978\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 15s 258us/sample - loss: 0.0087 - acc: 0.9976\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 16s 259us/sample - loss: 0.0066 - acc: 0.9981\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 16s 261us/sample - loss: 0.0087 - acc: 0.9977\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 16s 266us/sample - loss: 0.0079 - acc: 0.9978\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 16s 267us/sample - loss: 0.0056 - acc: 0.9983\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 16s 264us/sample - loss: 0.0091 - acc: 0.9977\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 16s 265us/sample - loss: 0.0055 - acc: 0.9985\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 16s 261us/sample - loss: 0.0074 - acc: 0.9981\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 16s 259us/sample - loss: 0.0056 - acc: 0.9985\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 16s 263us/sample - loss: 0.0053 - acc: 0.9984\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 15s 256us/sample - loss: 0.0083 - acc: 0.9979\n",
            "10000/10000 [==============================] - 1s 106us/sample - loss: 0.1481 - acc: 0.9815\n",
            "[1.7404750e-21 1.3810216e-21 2.1092345e-18 4.7659425e-18 2.8823690e-31\n",
            " 1.8258435e-25 2.0781773e-30 1.0000000e+00 1.2358948e-24 1.4696987e-19]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "korf8cH6SI5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# not standardizing the dataset before training. \n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# getting the dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# loading the dataset into different variables\n",
        "(training_images, training_labels), (testing_images, testing_labels) = mnist.load_data()\n",
        "\n",
        "# standardizing the dataset to have 0's and 1's\n",
        "# training and testing images has numbers between 0 and 255\n",
        "#training_images = training_images/255.0\n",
        "#testing_images = testing_images/255.0\n",
        "\n",
        "# designing the model\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                            tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "                            tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "# building the model\n",
        "model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', \n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# fitting the training data to the training labels\n",
        "model.fit(training_images, training_labels, epochs = 5)\n",
        "\n",
        "# evaluating the accuracy of the model using testing data to see how well our\n",
        "# system was trained. \n",
        "model.evaluate(testing_images, testing_labels)\n",
        "\n",
        "# creating a classification for each of the test images. \n",
        "# The classification let's us know the probability of \n",
        "# which label the test image belongs to. is it a shoe, shirt, \n",
        "# but in this case, the classification is not shoe, shirt, e.t.c\n",
        "# but rather it is a number. \n",
        "# We are testing to see if our model can \n",
        "# classify the images into the appropriate categories/labels\n",
        "\n",
        "classifications = model.predict(testing_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(testing_labels[0])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tAjEmicdho6",
        "colab_type": "text"
      },
      "source": [
        "Earlier when you trained for extra epochs you had an issue where your loss might change. It might have taken a bit of time for you to wait for the training to do that, and you might have thought 'wouldn't it be nice if I could stop the training when I reach a desired value?' -- i.e. 95% accuracy might be enough for you, and if you reach that after 3 epochs, why sit around waiting for it to finish a lot more epochs....So how would you fix that? Like any other program...you have callbacks! Let's see them in action..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VzIrINmdRKp",
        "colab_type": "code",
        "outputId": "6218b6b9-6e94-4b3f-bb55-871442dfb742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('loss')<0.3):\n",
        "      print(\"\\nLoss is low so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "      \n",
        "callbacks = myCallback()\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (testing_images, testing_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "testing_images = testing_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                  tf.keras.layers.Dense(512, activation = tf.nn.relu),\n",
        "                                  tf.keras.layers.Dense(10, activation = tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n",
        "\n",
        "#model.predict(testing_images, testing_labels)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 10s 170us/sample - loss: 0.4726 - acc: 0.8333\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 11s 180us/sample - loss: 0.3603 - acc: 0.8685\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 11s 176us/sample - loss: 0.3214 - acc: 0.8813\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 10s 170us/sample - loss: 0.3006 - acc: 0.8893\n",
            "Epoch 5/5\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.2811 - acc: 0.8950\n",
            "Loss is low so cancelling training!\n",
            "60000/60000 [==============================] - 11s 175us/sample - loss: 0.2810 - acc: 0.8950\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f52f6ba3c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONVCz0buhtfX",
        "colab_type": "text"
      },
      "source": [
        "**Alternative to the code above**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKkB3zubhwPx",
        "colab_type": "code",
        "outputId": "0529356d-d3e1-4892-9f9f-cdcbe25a81a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.89): #this is the difference from the code above\n",
        "      print(\"\\nReached 89% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "      \n",
        "callbacks = myCallback()\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (testing_images, testing_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "testing_images = testing_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                  tf.keras.layers.Dense(1024, activation = tf.nn.relu),\n",
        "                                  tf.keras.layers.Dense(10, activation = tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])\n",
        "\n",
        "#model.predict(testing_images, testing_labels)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 16s 272us/sample - loss: 0.4695 - acc: 0.8316\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 17s 276us/sample - loss: 0.3590 - acc: 0.8684\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 16s 268us/sample - loss: 0.3214 - acc: 0.8827\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 16s 266us/sample - loss: 0.2953 - acc: 0.8896\n",
            "Epoch 5/10\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.2800 - acc: 0.8966\n",
            "Reached 90% accuracy so cancelling training!\n",
            "60000/60000 [==============================] - 16s 267us/sample - loss: 0.2800 - acc: 0.8966\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f52f69195f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    }
  ]
}